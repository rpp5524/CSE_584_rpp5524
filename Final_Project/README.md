# CSE 584 Final Project - Faulty Science Questions for LLMs 

## My Details
- Name: Rohan Prasad 
- PSU ID: 980707395
- PSU email: rpp5524@psu.edu

## Project Overview
This project aims to collect and create a set of faulty science questions designed to challenge and potentially fool top-performing large language models (LLMs) such as ChatGPT, GPT4, Gemini-1.5-Pro, and Claude-3-Opus. These questions will contain logical flaws or inconsistencies that make them difficult for LLMs to handle correctly.

## Objectives
- **Create**: Create and collect new faulty questions that contain subtle logical errors or inconsistencies.
- **Test**: Evaluate the performance of several LLMs on these faulty questions to see how they handle logical pitfalls.

## Methodology
1. **Question Collection**: Use various online resources and educational platforms to find what LLMs find difficult to do.
2. **Question Creation**: Utilize brainstorming sessions to invent new questions that feature common logical errors or paradoxes.
3. **Model Testing**: Input these questions into different LLMs and record their responses for analysis.

## Tools and Resources
- **LLMs Access**: APIs or online interfaces for models like ChatGPT, GPT4, etc. I will be using locally hosted LLMs via Ollama as well
- **Documentation**: Notes and guidelines on crafting logically inconsistent questions.

## Expected Outcomes
- A comprehensive list of faulty science questions.
- Analysis of LLM responses to these questions to understand how models deal with flawed logic.
- Draft interesting research questions regarding the dataset that I collected.
-  Design solid and well defined experiemnts to answer those interesting research questions.



